---
title: "Predicting Credit Ratings with Machine Learning Algorithms"
author: "Valentina Guerra"
date: "23/6/2021"
output: word_document
---
<!-- This Rmd file is knitted in MS Word and transformed to a pdf subsequently, due to compliance reasons not allowing to install Latex on my work laptop. Edx staff approved this shortcut. -->

## Introduction and Overview

When taking decisions about capital allocation, investors are interested about the probability to collect back their money at a point in time in the future. However, they may not have the capacity or the information necessary to assess the ability of a targeted business to repay their money back in the future. In this case, they rely on credit assessments performed by other entities, like credit ratings. 

A credit rating is a forward-looking opinion of a private agency about an obligor's creditworthiness, i.e. their capacity and willingness to meet their financial obligations when they come due. Credit agencies are independent providers of these opinions, meaning that they have access to private information that investors don't and they are not involved in the process of capital allocation, so that their opinions remain truly independent. A credit rating is expressed through a combination of letters, combined with numbers or '+/-' signs depending on the agencies. They express a relative ranking of creditworthiness, in a scale going from 'AAA' (the best rating possible) to 'D' (the company is in default)^[Throughout this paper, the Standard & Poor's Rating Services (S&P) rating scale will be used as reference. Egan-Jones Rating Companies and DBRS use the same rating scale as S&P.].

```{r Rating scale, echo=FALSE, fig.cap="Fig. 1: Rating scale for primary rating agencies.", out.width="30%"}
knitr::include_graphics("Image.jpg")
```

Despite the criticisms around rating agencies' role during the Global Financial Crisis on 2008-2009, credit ratings remain extensively used by a variety of stakeholders. Institutional and individual investors use credit ratings to assess the risk related to a specific issuer or of a portfolio. Under certain circumstances, regulation or private contracts forbid them to invest in securities rated above or below a certain threshold. Intermediaries such as investment banks use credit ratings to finetune the final price offering of a financial instrument. Debt issuers request credit ratings to understand their relative ranking of creditworthiness in globalized capital markets.

Credit agencies work on a issuer-paid model, meaning that the company that will receive the final rating initiate the rating process, providing confidential information to credit analysts, so that they will have all necessary information to assess their creditworthiness with accuracy and thoroughly. It is a private business decision of a company to request a rating and not an obligation. Issuers of financial instruments can participate in capital markets without credit ratings. This means that investors do not have credit ratings to rely on for all the possible placement opportunities and they cannot always compare the creditworthiness of the obligors they decide to trust with others.

In this paper, we will build a machine learning algorithm that allow to predict the rating of a company, based on financial ratios that are publicly available in their financial statements. This model will allow investors to predict a rating for a company that is not evaluated by a credit agency and better assess the credit quality of a company prior to their investment decisions. Depending on the granularity of the model, they will be able to compare to other investments and build portfolios of different credit exposures. **Describe the structure of the report**

## Methods

### 1. The dataset

This work is based on a public dataset of corporate credit ratings, available on Kaggle^[The dataset can be found [here.](https://www.kaggle.com/agewerc/corporate-credit-rating)]. The dataset contains 2029 observations of 31 variables (of which 25 financial variables). The variables can be grouped into: general features, liquidity measurement ratios, profitability indicator ratios, operating performance ratios, debt (or leverage) ratios, cash flow indicator ratios and one valuation ratio. 

The _general features_ include the following variables:

- **Rating** : a character variable, the ratings expressed in rating scale. This is the variable that the machine learning algorithms will have to predict.
- **Name**: a character variable, the name of the company receiving the rating.
- **Symbol**: a character variable, the ticker of the company, meaning their trading symbol in their respective markets of reference.
- **Rating.Agency.Name**: a character variable, the rating agency assigning the rating.
- **Date**: a character variable representing the date of rating assignment.
- **Sector**: a character variable representing the sector in which the rated company operates.
- **effectiveTaxRate**: a numeric variable, expressing the average tax rate on a company's profits. It is computed by diving the tax expense to the earning before taxes (EBT) of a company.

$$Effective\,Tax\,Rate = \frac{Tax Expenses}{EBT}$$

The _liquidity measurement ratios_ include the following variables:

- **currentRatio**: a numeric variable, expressing the ratio between current assets and current liabilities. Current assets represent the assets that could be liquidate easily within one year. These include cash or equivalents, inventories and accounts receivable from clients that benefited from a deferral of payment for the purchase of good or services that the company offers. Current liabilities represent the obligations that the company has to satisfy within one year. These include short-term debt and accounts payable to suppliers to which the company purchased raw inputs and received a credit and employees. A current ratio greater than 1 means that the company has enough cash to meet its short-term obligations without the need to borrow.  

$$Current\,Ratio = \frac{Current\,Assets}{Current\,Liabilities}$$

- **quickRatio**: a numeric variable, representing a stringent version of the current ratio. This ratio compares only cash and cash equivalents (liquid short-term investments, like placements in the money market or government securities) to current liabilities. Inventories and accounts receivable are excluded: the former may not be liquid, the latter depends on the clients' creditworthiness itself. This ratio can be interpreted as the liquidity available to the company to repay their short-term obligations. 

$$Quick\,Ratio = \frac{Cash\,and\,cash\,equivalents}{Current\,Liabilities}$$

- **cashRatio**: a numeric variable. This is the most stringent of all liquidity measurements, as it only takes into account the cash of the company (meaning the total balance of their bank accounts) to current liabilities. It gives an indication of the cash position of the firm. 

$$Cash\,Ratio = \frac{Cash}{Current\,Liabilities}$$

- **daysOfSalesOutstanding**: a numeric variable. This variable represents the average number of days in a year the company needs to receive a cash payment for the sale of products or services. A low number means that the company can transform products or services into cash very quickly, while a high number means that it takes more time to receive cash flows for their operations. This ratio is influenced by the sector in which the company operates and its seasonality, but also the commercial strategies in place (e.g. a promotional sales or generous credit terms may influence negatively this ratio).

$$Days\,of\,Sales\,Outstanding = \frac{Accounts\,Receivables}{Average\,Daily\,Sales}$$

- **payablesTurnover**: a numeric variable. This variable represents the rate at which accounts payable are paid during one year. It is a measure of short-term liquidity, as accounts payable represent short-term debt that the company uses to finance day-to-day operations. It is computed by dividing the total amount of supply purchase during the year by the average amount of accounts payable in a year (the average between beginning and end of the year). It expresses how many times in a year the company can repay its suppliers^[Both the Days of Sales Outstanding and the Payable Turnover Ratio can be expressed using different periods (e.g. on a monthly, quarterly or semi-annual basis). As I do not have access to the formulas used by the dataset creators, I assume the ratios are computed on a yearly basis, given the values of the variables.]. 

$$Payables\,Turnover = \frac{Total\,Yearly\,Supply\,Purchase}{Average\,Accounts\,Payable}$$

The _profitability indicator ratios_ include the following variables:

- **netProfitMargin**: a numeric variable indicating the ratio between net profit (the bottom line of income statement) to total sales. This ratio can be interpreted as the percentage of revenues available to shareholders, after paying interests and taxes.

$$Net\,Profit\,Margin = \frac{Net\,Profit}{Total\,Sales}$$

- **pretaxProfitMargin**: a numeric variable, the ratio between profit before taxes to total sales. It is an indication of the percentage of revenue that has turned into a profit, before deducting taxes.

$$Pretax\,Profit\,Margin = \frac{Pretax\,Profit}{Total Sales}$$

- **grossProfitMargin**: a numeric variable, also called gross margin. This is the ratio between gross profit (i.e. the difference between total sales and cost of sales) and total sales, expressed as a percentage. It gives an indication of the profitability of the company's core business (or topline), meaning how efficient is the company in selling a product or a service for more than the costs of production. 

$$Gross\,Profit\,Margin = \frac{Gross\,Profit}{Total\,Sales}$$

- **operatingProfitMargin**:a numeric variable, also called operating margin. The operating margin is the ratio between operating profit (i.e. the difference between gross profit and additional expenses necessary to run the business but not related to production, like selling and administrative expenses, research and development or depreciation and amortization.) to total sales. This ratio represents the percentage of revenue that the company retains after taking into account all necessary costs to operate the business and before paying interest and taxes. The gross margin and the operating margin are the most useful ratios in comparing the profitability of two firms operating in the same sector. 

$$Operating\,Profit\,Margin = \frac{Operating\,Profit}{Total\,Sales}$$

- **ebitPerRevenue**: a numeric variable, also called EBIT margin. This is the ratio between earnings before interest and taxes (EBIT) to total sales. EBIT is computed by adding back to net income interest and tax expenses. Although operating profit and EBIT are often used as synonyms, operating profit does not include non-operating income or expenses, such as the profit from selling a production plants, which are reported below the operating income in the income statement. Like the operating profit margin, the EBIT margin is a profitability measure that does not take into account the effect of taxes and interests. 

$$EBIT\,margin = \frac{EBIT}{Total\,Sales}$$

The _operating performance ratios_ include the following variables:

- **returnOnAssets**: a numeric variable expressing the ratio between net income and the value of assets on the balance sheet (both current assets and long-term assets)^[As I do not have access to the formulas to compute the ratio, this is an assumption. Another way to compute the return on asset is to add interest expenses to net income before dividing by the total assets, as the denominator is funded through both debt and equity.] as a percentage. This ratio expresses the efficiency or the ability of the company to use their assets to generate profit.

$$Return\,on\,Assets = \frac{Net\,Income}{Total\,Assets}$$

- **returnOnCapitalEmployed**: a numeric variable, expressing the ratio between EBIT and capital employed, which is computed as the difference between total assets and current liabilities as a percentage. As the balance sheet of the company is an identity, capital employed also represents the sum between shareholder's equity and long-term debt obligations. This ratio expresses the efficiency or the ability of the company to generate operating profit using both sources of capital at its disposal.

$$Return\,on\,Capital\,Employed = \frac{EBIT}{Total\,Assets - Current\,Liabilities}$$

- **returnOnEquity**: a numeric variable. This is the ratio between the net income and the shareholder's equity as a percentage. This ratio expresses the ability of the company to generate a return for its shareholders.

$$Return\,on\,Equity = \frac{Net\,Income}{Equity}$$

- **assetTurnover**: a numeric variable. This is the ratio between total sales and total assets^[Assuming it is the value of total assets in the balance sheet. The denominator can also be computed as the average assets in a year.]. It measures the efficiency of the company in generating revenue from its assets.

$$Asset\,Turnover = \frac{Total\,Sales}{Total\,Assets}$$

- **fixedAssetTurnover**: a numeric variable. This represents the ratio between the total sales and total fixed assets, i.e. property, plants and equipment. These assets usually represent the core of the production plants of the company and the ratio measures the efficiency of the company in generating revenue from this kind of assets. For sectors in which fixed assets are not relevant (for instance food retailers merely distributing products or for service-focused industries), this ratio is not much informative.

$$Fixed\,Assets\,Turnover = \frac{Total\,Sales}{Total\,Fixed\,Assets}$$

The _debt (or leverage) ratios_ include the following variables:

- **debtEquityRatio**: a numeric variable. This ratio expresses the numerical relationship between debt and equity (computed either with book values or market values). It is a common measure to understand the amount of leverage and its weight among the company's sources of financing.

$$Debt\,Equity\,Ratio = \frac{\,Book\,Value\,of\,Debt}{Book\,Value\,of\,Equity}$$

- **debtRatio**: a numeric variable. This is the ratio between total debt to total assets, expressed as a percentage. It gives an indication of the proportion of the company's assets that are financed through debt. It is very sensitive to industry in which the company operates, as capital-intensive industries have higher ratios than services sectors.

$$Debt\,Ratio = \frac{Total\,Debt}{Total\,Assets}$$

- **companyEquityMultiplier**: a numeric value. The equity multiplier, computed using either book value or market value^[Here assumed as book value.] of total assets and equity, expresses the enhancement or the amplification of total return to equity that results from leverage, since assets are financed through both debt and equity.

$$Equity\,Multiplier = \frac{Total\,Assets}{Book\,Value\,of\,Equity}$$

The _cash flow indicator ratios_ include the following variables:

- **freeCashFlowOperatingCashFlowRatio**: a numeric variable. Free cash flow represents the cash flow that is available to the company's shareholders or debtholders, after taking into account the expenses the company has to sustain in order to support the long-term development of the business, i.e capital expenditures (capex). It is a better representation of 'cash profitability' of a company's, as it does not include non-cash elements that are included in the income statement (like depreciation and amortization which is a non-cash expense included in the operating profit). Operating cash flow is a measure of cash generated by the company's core operations, which should be high enough to allow the company to sustain its investments, interest payments and shareholders distributions. The ratio of free cash flow to operating cash flow, expressed as a percentage, is a good indication of how much of cash available to capital providers is embedded in operating cash flow. The higher the ratio, the stronger the financial position of the company, as it means that the company has a significant amount of resources to invest in future growth and repay investors.

$$Free\,Cash\,Flow\,to\,Operating\,Cash\,Flow\,Ratio = \frac{Free\,Cash\,Flow}{Operating\,Cash\,Flow}$$

- **freeCashFlowPerShare**: a numeric variable, expressing the free cash flow available to shareholders on a per-share basis. It gives an indication of potential dividends or future share prices.

$$Free\,Cash\,Flow\,per\,Share = \frac{Free\,Cash\,Flow}{Numbers\,of\,shares\,outstanding}$$

- **operatingCashFlowPerShare**: a numeric variable, expressing the operating cash flow available to shareholders on a per-share basis.It gives an indication of potential cash available to shareholders from the core operations of the company.

$$Operating\,Cash\,Flow\,per\,Share = \frac{Operating\,Cash\,Flow}{Numbers\,of\,shares\,outstanding}$$

- **operatingCashFlowSalesRatio**: a numeric variable, also called operating cash flow margin. It is the ratio of operating cash flow to total sales and it gives an indication on how efficient the company is in transforming sales from core operations into cash. 

$$Operating\,Cash\,Flow\,Margin = \frac{Operating\,Cash\,Flow}{Total\,Sales}$$

- **cashPerShare**: a numeric variable, expressing the potential amount of dividend per share of a company.

$$Cash\,per\,Share = \frac{Cash\,and\,cash\,equivalent}{Numbers\,of\,shares\,outstanding}$$

And finally, one _valuation ratio_:

- **enterpriseValueMultiple**: a numeric variable. This ratio can be computed as the ratio  of the enterprise value to the earnings before interests, taxes, depreciation and amortization or EBITDA^[As I do not have access to the formulas used to compute the ratios, this is an assumption. The Enterprise Value Multiple can be expressed in a variety of different ways (e.g. using EBIT or Gross Profit instead of EBITDA) but the EBITDA multiple is the most common evaluation methods among finance professionals.]. Enterprise value is computed either by taking the sum of debt and equity (using book values) or by deducting the value of debt from the market capitalization of the company (using market values). The EBITDA is a quasi-cash assessment of the financial performance of the company and it is computed by adding back depreciation and amortization to EBIT. The Enterprise Value Multiple is used by potential buyers to determine the price of a target company.

$$Enterprise\,Value\,Multiple\,(EBITDA\, Multiple) = \frac{Enterprise\,Value}{EBITDA}$$

These ratios will have different levels of relevance in predicting the ratings, as not all of them are relevant for a credit analysis standpoint. Rating analysts follow strict methodologies which are publicly available. The methodologies give more relevance to leverage ratios, cash flow indicator ratios and interest coverage ratios.

### 2. Exploratory Data Analysis

Before starting to gain insights on the data, we need to check whether there are missing values ("n/a") in the dataset. Using the function __is.na__ applied to the entire dataset, we can observe that there are no missing values in the dataset.
Moreover, by analyzing the structure of the dataset, we can observe that the __Date__ variable, containing the year of rating assignment is a character variable. Transforming this variable into a date will make exploratory operations easier.

The dataset contains 2029 ratings on 593 companies, given by 5 different rating agencies, from 2005 to 2016. 
```{r preliminary structure, echo=FALSE}
load("ML_credit_ratings_workspace.RData")
knitr::kable(prelim_structure)
```

Ratings were assigned over a span of 11 years, but in reality the time distribution of the dataset is uneven. No ratings in the dataset were assigned between 2005 and 2009, and the majority of ratings is concentrated between 2012 and 2016:

```{r date_dist, echo=FALSE}
knitr::kable(date_dist)
```

We can observe that some rating agencies are more active than others. Indeed, by studying the number of ratings per rating agencies, we can observe that 94.9% of ratings are given by three companies: Standard & Poor's (S&P), Moody's Investors Service (Moody's) and Egan-Jones Ratings Company (EJR).  

```{r rating_by_agency, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
ggplot(data, aes(Rating.Agency.Name, fill = Rating.Agency.Name)) + 
  geom_bar() +
  labs(y = "Number of ratings provided", title = "Ratings distribution per rating agency") +
  guides(fill=guide_legend("Rating Agency")) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) 
```

This is coherent with the reality of the credit rating market, which is very concentrated. S&P and Moody's together have a market share of more than 70%^[Data as of December 2020, European Securities and Markets Authority (ESMA) calculation. [Source.](https://www.esma.europa.eu/press-news/esma-news/esma-reports-annual-market-share-credit-rating-agencies-0)]. It is interesting to observe that, according to ESMA's computation, Fitch Ratings (Fitch) is considered to be the third largest credit agencies by market share, while in the dataset, it is Moody's who holds this position. Moreover, EJR does not appear among the rating agencies of ESMA's consideration. This is due to the fact that the dataset is composed of U.S. companies and, while both agencies serve global markets, EJR is concentrated in the U.S., while Fitch is more active on European companies. 

Not all companies are rated by all rating agencies and some companies have multiple credit ratings from the same rating agency^[There are 593 companies in the dataset. The distribution is provided only in the R file.]. It is the company that decides how many rating agencies should rate them and rating agencies are responsible for the oversight, or surveillance, of the rating of the company, meaning that they can change the rating multiple times in a given year, if the creditworthiness of a company changes (e.g. after announcing an acquisition or divesting a business line).

Finally, we can see that some sectors receive more ratings than others:

```{r rating_by_sector, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
ggplot(data, aes(Sector, fill = Sector)) + 
  geom_bar() +
  labs(y = "Number of ratings", title = "Ratings distribution per sector") +
  guides(fill=guide_legend("Sector")) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

Some sectors have different forms of market organization and will need less ratings than other. For instance, the transportation sector includes companies that benefit from state monopolies, such as FedEx Corp. or the Canadian National Railway Company. For these companies, there is less volatility of creditworthiness, as there are less opportunities in the business itself.

We now study the distribution of the predicted variable: the credit rating. From a bar plot of the number of ratings by rating category, we can observe that the dataset is unbalanced: very few companies receive ratings above A or below CCC. 
```{r , echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
data1 <- data %>% mutate(Rating = factor(Rating, levels = c( "AAA", "AA", "A", "BBB", "BB", "B", "CCC", "CC", "C", "D")))
```

```{r rating_by_category, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
ggplot(data1, aes(Rating, fill = Rating)) +
  geom_bar() +
  labs(y = "Number of ratings", title = "Ratings distribution per rating category") +
  guides(fill=guide_legend("Rating Category (ordered)")) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) 
```

This is related to the fact that the best and the worst ratings possible are 'extremes' in financial markets: few companies can hold up to standards of perfect rating quality and companies in distress do not make the majority of enterprises in the U.S.. Indeed, the best rated companies up to 2016 were Microsoft, Johnson & Johnson and Union Pacific Corporations. These are very lucrative companies, benefiting from monopolies in their respective market and with a sound management of their finances. The worst rated companies up to 2016 in the datset include, among others, California Resources Corp., which filed for bankruptcy in July 2020 under the weight of their debt burden and Caesars Entertainment Corp. which filed for bankruptcy in 2015 and endured many hurdles during its lifetime. 

Looking at individual rating categories may not be the most informative way to think about credit ratings. Indeed, there is an "informal" rating classification to which investors rely on: the distinction between _investment grade (IG) rating_ and _speculative (or high yield, Non-IG) grade rating_. All ratings above BBB- included are considered investment grades, while all ratings below BB included are considered speculative grade. Investment grades are considered safer investments, consequently paying lower yield on their debt offerings. Speculative grades are riskier companies, which pays higher margins on their debt instruments to attract investors. We can map the dataset to this distinction using a binary variable, called __Category__: "IG" for investment grades and "Non-IG" for speculative grades. Using this distinction, the dataset seems more balanced: 57.4% of ratings are investment grades and 42.6% are speculative grades. The more balanced the dataset, the better the precision of algorithms we can build using it.

```{r rating_macrodist, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
data_bin %>% mutate(Category = as.factor(Category)) %>%
  ggplot(aes(Category, fill = Category)) +
  geom_bar() +
  labs(y = "Number of ratings", title = "Number of investment (IG) and speculative grades (Non-IG) ratings") +
  guides(fill=guide_legend("Category")) +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(), 
        plot.title = element_text(size = 10))
```

When studying the distribution between IG and Non-IG, a natural question that we could ask ourselves is: are rating agencies biased, i.e. some of them give systematically higher ratings, while others tend to be more conservative? By plotting the proportion of IG and Non-IG ratings grouped by rating agency we can observe that there is a bias.

```{r , echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
library(plyr)
library(dplyr)
b <- data_bin %>% select(Category, Rating.Agency.Name)
b

#Require plyr
c = ddply(data.frame(table(b)), .(Rating.Agency.Name), mutate, pct = round(Freq/sum(Freq) * 100, 1))

```

```{r rating_by_category_and_agency, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
ggplot(c, aes(x = Category, y = Freq, fill = Rating.Agency.Name)) + 
  geom_bar(stat = "identity", width = .7) +
  geom_text(aes(label = paste(c$pct, "%", sep = "")), vjust = -1, size = 3) +
  facet_wrap(~ Rating.Agency.Name, ncol = 2) + 
  scale_y_continuous(name = "Count", limits = c(0, 1.3*max(c$Freq))) +
  theme(legend.position = "none")
```

Leaving aside DBRS for which the number of ratings in the dataset is not significant to comment on its bias, Fitch, Moody's and particularly EJR seem to be more generous than S&P, which has a higher proportion of speculative grades among its ratings. This bias needs to be accounted for when constructing a prediction algorithm that takes the rating agency as a predictor. 

Another natural questions that arise regards the distribution between IG and Non-IG by sector. By plotting the proportion of IG and Non-IG ratings grouped by sector, we can observe that the distribution is not even:

```{r , echo=FALSE, include=FALSE, message=FALSE, warning=FALSE}
d <- data_bin %>% select(Category, Sector)

e = ddply(data.frame(table(d)), .(Sector), mutate, perct = round(Freq/sum(Freq) * 100, 1))

```

```{r rating_by_category_and_sector, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
ggplot(e, aes(x = Category, y = Freq, fill = Sector)) + 
  geom_bar(stat = "identity", width = .7) +
  geom_text(aes(label = paste(e$perct, "%", sep = "")), vjust = -1, size = 2) +
  facet_wrap(~ Sector, ncol = 2) + 
  scale_y_continuous(name = "Count", limits = c(0, 1.6*max(e$Freq))) +
  theme(legend.position = "none")
```

We can observe that there are sectors for which investment grades companies are very common and other for which non-investment grades make the majority of rated companies. As explained above, some sectors are associated with a higher level of creditworthiness because they benefit from particular economic conditions that results in barriers of entry for the concurrence and more stable financials. 

We now study the financial variables that we will use as predictors. In the previous sections, we identified six categories to group the financial ratios that are given in the dataset: liquidity measurement ratios, profitability indicator ratios, operating performance ratios, leverage ratios, cash flow indicator ratios and valuation ratio.  We study the summary statistics^[The tables with the summary statistics for all classes of ratios can be found at the end of the report, in the Appendix Section.] of the financial ratios using this macro classification.

#### _Liquidity Ratios_

From a first glance at descriptive statistics for liquidity ratios, we can see that the variability among these variables is quite high. Indeed, the range span is very large, the standard deviation is very high for all variables and the mean and median differs significantly. Is this variability a common feature of the data or is it influenced by outliers? A glance at the boxplot for these ratios shows a distortion caused by large outliers. To determine whether a value is an outlier, we use the Tukey's definition. An outlier is defined as the value that is outside 1.5 times the interquantile range (i.e the difference between the first quantile and the third quantile). Using this definition, we can count the numbers of outliers for each of the variable considered:

```{r liquidity_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(liquidity_stats2, digits = 2)
```

The number and the value of outliers has a significant influence on the distribution of these variables, which is then skewed and driven away from the normal distribution.

#### _Profitability Indicator Ratios_

The pattern of high variability and a high number of outliers is repeated for profitability indicator ratios, except for the Gross Profit Margin, which shows a low standard deviation and a lower count of outliers.

```{r profitability_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(profitability_stats2, digits = 2)
```

Nevertheless, when the value of volatility is compared to other variables, it can be described as quite low. This is due to the fact that these are standardised variables, which do not take into account different usage of accounting standards, as they use macro categories always present in an income statement. The variability can be due to differences among sectors.  

#### _Operating Performance Ratios_

Operating performance ratios are the class of financial ratios showing the greatest volatility. Indeed the value of standard deviation spikes for all ratios, even though the count of outliers is lower compared to other ratios such as liquidity ratios. 

```{r operating_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(operating_stats2, digits = 2)
```

The volatility of operating performance ratios can be explained by the difference in accounting standards used to compute the financials. For instance, the asset category on the balance sheet is influenced by the asset recognition policy of the company itself. Exceptional years cal also influence the volatility of these ratios (e.g. an extraordinary sale of assets).

#### _Leverage Ratios_

Among the leverage ratio, the debt ratio shows a lower value of standard deviation and a lower count of outliers, while the debt-to-equity ratio and the company equity multiplier seem to have values that are very close.

```{r leverage_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(leverage_stats2, digits = 2)
```

The two ratios are close when the value of debt is very low.

#### _Cash Flow Indicator Ratios_

Among the cash flow indicator ratios, those showing the greatest amount of volatility and the greatest amount of outliers are those computed on a per-share basis. 

```{r cashflow_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(cashflow_stats2, digits = 2)
```

This is due to the great variability of the denominator. Indeed, not all company have the same amount of share issued. Moreover, the cash flow of a company can vary greatly from one year to the other, based on their financial policy, investments and revenue from their operations.

#### _Valuation Ratio_

Finally, for the valuation ratio we can observe that the range is very large, the standard deviation very high and there is a great distance between the mean and the median.

```{r valuation_stats2, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(valuation_stats2, digits = 2)
```

Indeed, targets' valuation can vary greatly depending on the financial situation of the company being acquired (distressed vs. financially sound company) and the context in which the company is bought (opportunistic M&A vs. friendly merge). 

### 3. Building the algorithms

#### 3.1 Preprocessing and problem setting

Before starting to develop the algorithms to predict the ratings, we need to preprocess the data and make the dataset more suitable to the machine learning challenge we are going to face. 

We already checked for missing values in the previous section and we found none. We can also check whether we can remove some of the ratios to make the dataset lighter as 32 predictors will have an impact on the performance of the algorithms. Some ratios may be identical or used as synonyms and it may be not necessary to keep all of them. By a visual inspection of the dataset, we can observe that the variables __pretaxProfitMargin__ and __ebitPerRevenue__ seems identical. However, a  comparison of these variables tells us that they are not identical in all instances: around 90.8% of cases are identical but there is a 9.2% that is not. This suggests that many companies in the dataset pay little interests on their debt obligations. 
Moreover, as operating profit and EBIT are sometimes used as synonyms, we check whether the variables are identical. This is the case in only 13.3% of instances, meaning that they can't be considered identical for this dataset.

In the previous section, we pointed out the great influence of outliers on the distribution of predictors. Since we do not know much about how the dataset was constructed, we cannot distinguish whether the outliers are due to data entry errors, measurement errors or any other reasons. However, it is important to notice that working with outliers is very common in corporate finance. Outliers can be a result of one year of extremely bad or good results, which can affect the value of accounting entries and therefore the ratios that are computed based on it. Changing account rules can also be accounted for the variability of the time series of ratios of a company. Transformative operations such as acquisitions, carve-out, divestment can also have a great impact on accounting measures. These factors are considered by rating agencies when assigning a credit rating and consequently influence their outcome. Therefore, we do not remove outliers from the predictors and we will assess later the consequences of this choice on the algorithms' performance.

As stated in the previous section, not all financial ratios are relevant to determine a credit rating. Rating agencies are focused on the creditworthiness of the companies, i.e. their ability to repay their lenders. Hence, the methodologies they use give more importance to some ratios, in particular that are most useful when taking the perspective of a debt investors. The dataset is composed of 1 predicted variable and 30 predictors, both general features and financial ratios. Among the general features, the most important ones are the name of the company __Name__, the __Rating.Agency.Name__ to account for the bias, and the __Sector__ in which the company operates. 
Among these general features, we keep the rating agency assigning the rating and the company's sector. Keeping the name of the company will result in model overtraining. 
Liquidity is an important element in a rating analysis, as rating agencies assess whether the company has enough cash to pay their due obligations and debt servicing. Therefore, we keep all of liquidity ratios. Profitability measurements are also important in a rating analysis, as they are used by rating agencies to understand the performance of the company in its sector and its ability to generate profit from its core operations. The operating performance ratios are very important for the shareholders of the company, as they indicate whether a company is able to generate a return for equity holder, but they are of little interest for debt investors and are consequently removed. Debt ratios are very important as they summarize in one number the capital structure of the company but the __companyEquityMultiplier__ can be removed as it is important for shareholders, but not for lenders. Cash flow indicator ratios are of great importance for a rating analysis, as they give an indication of how much cash the company generates from its operations, which is potentially available for the future debt repayment. However, many of the cash flow indicator ratios in the database are computed on a "per-share" basis, which is not informative to lenderes. Therefore, among these ratios, only __freeCashFlowOperatingCashFlowRatio__ and __operatingCashFlowSalesRatio__ are kept. Finally, the valuation ratios is excluded as predictor, as this is an indication of the potential profit to shareholders if they sell the company. The profit for lenders is represented by the interest rate margin on the debt instrument and this ratio is meaningless to them.

To recap, in addition to the predicted variable (__Rating__), the predictors (columns) that are kept from the original dataset to train algorithms are the following:

- **Rating.Agency.Name**
- **Sector**
- **currentRatio**
- **quickRatio**
- **cashRatio**
- **daysOfSalesOutstanding**
- **paybalesTurnover**
- **netProfitMargin**
- **pretaxProfitMargin**
- **grossProfitMargin**
- **operatingProfitMargin**
- **ebitPerRevenue**
- **debtEquityRatio**
- **debtRatio**
- **freeCashFlowOperatingCashFlowRatio**
- **operatingCashFlowSalesRatio**

The columns __Name__, __Rating.Agency.Name__ and __Sector__ are character variables and cannot directly be fed to an algorithm. We use the __dyplr__ package to convert them into factors.

The task of predicting credit ratings can be tackled under two angles. The first considers the informal distinction between investment and non-investment grade ratings that we defined above. In this case, the predicted variable is a binary categorical variable. The second one leverages on the fact that credit ratings are rank-ordered assessments of creditworthiness and therefore the credit rating to predict is an ordinal categorical variable. We will build different algorithms and use different models, according to the problem definition. 

#### 3.2 Problem n. 1: investment or speculative grade?

In this section, we leverage on the distinction between investment and speculative grades ratings. As mentioned above, all ratings above BBB- included are considered investment grade, while those below BB included are considered speculative grade. From an investor's perspective, this could allow to have a first screening about the company's creditworthiness and decide which companies include in which portfolio. 

We map the __Rating__ variable  in the dataset  using a binary variable called __Category__ (1 for investment grades and 0 for speculative grades). The algorithms in this section will have to predict whether the company will receive a speculative or investment grade rating.
We divide the binary dataset into a __train_set__ and a __test_set__: the train set will be used to train the algorithm, while the test set will be used to assess its performance. The selected size of the test set is 10% of the train set. The original dataset is made of 2,029 observations, which is not very large compared to other datasets we used in the course. Therefore, we try to maximize the amount of the data that algorithms can use to train and we make the test set smaller. 

##### Logistic regression

We start with a simple model: the __logistic regression__. The logistic regression is the most common linear approach to predict categorical data. We define the outcome $Y$ as 1 for investment grade rating (IG) and 0 for speculative grade rating (Non-IG). The logistic regression focuses on conditional probabilities:

$$Pr(Y = 1 |\, \mathbf X = x )$$
where $Y = 1$ represents the rating being an investment grade one and $\mathbf X$ represents the matrix of features and ratios we use as predictors. 

This model will tell us how much more likely is to receive an investment grade rating, given the sector in which the company operates, the rating agencies assigning the rating and the values of the selected financial ratios. To run the logistic regression model, we use the __glm__ function from the __caret__ package.

```{r logit, echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
logit <- glm(Category ~ ., data = train_set, family = "binomial"(link = "logit"), maxit = 100)
summary(logit)

```

From a glance at __summary(logit)__, we can see which of the predictors are statistically significant. The rating agencies assigning the rating have very high levels of p-value and cannot be considered as among the determinant factors increasing the probability of receiving an investment grade. Among sectors, those who are statistically significant seems to be Capital Goods, Consumer Non-Durables, Finance, Miscellaneous and Public Utilities. However, these corresponds to the sectors with the highest representation of investment grade companies. As our sample data is unbalanced, the statistical significance of these sectors should be checked again with another sample. Among the ratios, those who seems to have statistical significance are the current ratio, cash ratio, pretax profit margin, ebit per revenue, the debt ratio and the operating cash flow to sales ratio.

We predict the probability of an investment grade assignment over the test set with the variable __p_hat_logit__. We then use these predicted probabilities to predict the rating outcome. In particular, we want to assess the performance of the method against guessing the outcome without knowing the value of the predictors, hence we set 0.5 as the probability cutoff to decide whether the company is IG or Non-IG. 

```{r logit2, echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
p_hat_logit <- predict(logit, test_set, type= "response") #response gives predicted probabilities
y_hat_logit <- factor(ifelse(p_hat_logit > 0.5, "IG", "Non-IG"))
```

With logistic regression, we achieve a level of accuracy of 28.43%, which is very low. This may be due to multicollinearity among the predictors. Indeed, by studying the correlation matrix for numeric predictors only,  we can observe that some predictors are highly correlated, for instance _EBIT per Revenue_ and _Net Profit Margin_. Having ratios that are highly correlated among each other is quite common in corporate data, as the financial metrics used to compute the ratios are build in waterfall (e.g. Net Profit includes EBIT in its definition as it is computed at an inferior level of the income statement). Logistic regression requires little or no multicollinearity among predictors, hence its poor performance.

We perform again logistic regression with only the predictors that were defined as statistical significant from the first model.
```{r logit3, echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
logit2 <- glm(Category ~ Sector + currentRatio + cashRatio + pretaxProfitMargin + ebitPerRevenue + debtRatio + operatingCashFlowSalesRatio,
              data = train_set, 
              family = "binomial"(link = "logit"), 
              maxit = 100)

p_hat_logit2 <- predict(logit2, test_set, type= "response")
rating_hat_logit2 <- factor(ifelse(p_hat_logit2 > 0.5, "IG", "Non-IG"))
```

The dimensionality reduction improves a little the performance, but it is still low: the accuracy level sets at 32.84% 

##### Quadractic discriminant analysis

We demonstrated that the logistic regression is not a good fit ofr the credit ratings data, even when controlling for the multicollinearity. This is due to the fact that logistic regression assumes the decision boundary to distinguish between the two categories (investment and non-investment grade) to be linear. We relax this hypothesis with the second algorithm for the problem, the __quadratic discriminant analysis (qda)__, which assumes the decision boundary to be quadratic. 

Since the _qda_ model does not perform well with a full set of 17 predictors, we build this model using only the predictors that were considered statistically significant for the second logistic regression model. 

```{r qda, echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
qda <- train(Category ~ Sector + currentRatio + cashRatio + pretaxProfitMargin + ebitPerRevenue + debtRatio + operatingCashFlowSalesRatio, 
             data = train_set, 
             method = "qda")

rating_hat_qda <- predict(qda, test_set) #default option gives predicted outcome
```

With qda, we achieve a level of accuracy of 62.74%, much higher than what we achieved with both versions of logistic regression. This suggest that models that do not consider the outcome to be a linear combination of the dependent variables will outperform the simplest models. 

##### K-nearest neighbors

The last algorithm we build to predict investment and non-investment grade ratings is the __k-nearest neighbors (knn)__ algorithm, which can be adapted easily to estimate the conditional probability of being investment grade. With this algorithm, we will estimate the average distance between features and ratios used to estimate the conditional probability of being investment grade on a neighborhood of size _k_. Knn is non-parametric approach, which means that it does not incorporate assumptions about the shape of the decision boundary.

We start using the default _k_ for the model, which is 5. In this case, for each set of features and variables, the algorithm will look at the 5 nearest points and predict the rating outcome (which can be seen directly with the option "class").

```{r knn, echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
knn <- knn3(Category ~ ., data = train_set, k = 5) #5 is the default
rating_hat_knn <- predict(knn, test_set, type = "class") #class gives the predicted outcome
```

With knn($k = 5$), we achieve a level of accuracy of 67.65%. As mentioned above, 5 is the default value for the __knn3__ function from the __caret__ package. What is the optimum value of _k_, the one that gives maximum accuracy? We can repeat the model testing on a sequence of _k_, going from 1 to 45, where 45 represents square root of the number of observations in the entire dataset:

```{r, echo=FALSE, include=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
ggplot(data_optk, aes(k, Accuracy)) +
  geom_point()
```

The plot suggests that we get maximum accuracy of 70.10% with $k = 3$.  

#### 3.3 Problem n. 2: predicting credit ratings

In this section, we leverage on the main advantage of credit ratings: they are rank-ordered assessments of creditworthiness, meaning that there is an order that the machine learning algorithms can exploit to predict credit ratings. 

We map the __Rating__ variable in the dataset using a numerical variable called __Credit__ that takes numbers from 1 to 10, where 1 is the equivalent to a 'AAA' rating (the best possible quality) and 10 is equivalent to a 'D' rating (the company is in default).

For this machine learning challenge, prevalence is an important issue that we cannot overlook. Prevalence refers the fact that some credit rating categories are more represented in the dataset than others, as demonstrated in the Exploratory Data Analysis section. In the previous machine learning challenge, the binarization of the __Rating__ variable improved the balance between categories, hence we could feed the machine learning algorithms with the entire dataset. In this challenge, balance cannot be achieved unless we drop the least represented rating categories in the dataset. Hence, the rating categories 'AAA', 'CC', 'C' and 'D' would not be part of the dataset, as they contain less than 10 observations. Hence, the algorithms will only be able to predict credit ratings from 'AA' (2) to 'CCC' (7), as these are the most represented categories in the dataset.

Finally, we will use cross validation in all models to determine the optimal value of models' parameters. Cross validation is performed using the __caret__ package and its build-in __train__ function, which is based on 25 bootstrap samples, meaning that we will have 25 bootstrap sample with 25% of the observation from the train set in it. For each model, we test a grid of values rather than the default options included in the train function.


##### K-nearest neighbors

We start by predicting the credit rating using the k-nearest neighbors algorithm, as this is the model that performed the best in the previous machine learning challenge. To determine the value of _k_, we test a sequence of values going from 1 to 45, with 45 being the square root of the number of observations in the dataset:

```{r , echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
knn_rating <- train(Credit ~ ., 
                    method = "knn",
                    data = train_set,
                    tuneGrid = data.frame(k = seq(1, 45, 1))) #We test this sequence to determine the optimum k.
```

The best model is the one using 1 neighbor and this correspond to a level of accuracy of 46.57%.

```{r , echo=FALSE, include=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
ggplot(knn_rating, highlight = TRUE)
```

Under this challenge, the level of accuracy achieved with the knn model is much lower compared to the same model in the previous section. The fact that the knn($k = 1$) is the one with the best accuracy means that, on one hand, the model is very unbiased (i.e. only the closest neighbor will be used to predict and the new predictions will have a high probability of being correct) but, on the other hand, the knn model for this dataset is very unstable and too close to the training set used.  In this case, the classifying procedure is too close to the random sampling in the dataset and we could only appreciate the performance of the model on average. Under this model, the accuracy is 46.57%, meaning that a guessing model will have a higher accuracy.

Finally, if we study the sensitivity and specificity for each credit rating, we can see that sensitivity is very low for all categories, meaning that the algorithm is not able to recognize a certain credit rating when it pertains to one category. This is especially true for the highest rating (2 which is 'AA' rating) and for the 6 category ('B' rating).

```{r , echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
cm_knn
```

##### Classification tree

The second model we will use to predict credit ratings is a classification tree, which partitions the predictor space and define decision rules to predict the final outcome. We use the train function from the caret package, the __rpart__ method to partition the predictor space and test a sequence from 0 to 0.1 to determine the optimal value of complexity parameter __cp__:

```{r , echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
class_tree <- train(Credit ~ ., 
                    method = "rpart", 
                    data = train_set,
                    tuneGrid = data.frame(cp = seq(0.0, 0.1, len = 25))) #we use cross validation to determine the optimum complexity parameter cp

```

The final model includes 8 partitions, with the optimal value of the complexity parameter defined using cross validation at 0.0125.

```{r , echo=FALSE, include=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
ggplot(class_tree, highlight = TRUE)
```

By plotting the decision tree, we can see that the model set the decision rules using the Net Profit Margin, the Rating Agency, the Pretax Profit Margin, the Cash Ratio, the Debt Ratio and the Gross Profit Margin as decision variable. It is interesting to notice that this model takes directly into account the rating agency bias we described in the Exploratory Data Analysis section.

```{r , echo=FALSE, include=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
plot(class_tree$finalModel, margin = 0.1)
text(class_tree$finalModel, cex = 0.50)
```

Despite this, even with the optimum complexity parameter, the performance of the classification is very low: the accuracy is only 40.68%. If we study the sensitivity and specificity of the model, we can see that this model has difficulties to detect the 'AA' rating (Class 2), as the previous model, and the 'CCC' rating (Class 7).

```{r , echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
cm_class_tree
```

##### Random Forest

The last model we will use to predict credit ratings is the random forest, which averages many decision trees built thorough a random process. We use the train function from the caret package, the __rf__ method for Random Forest and test a sequence from 2 to 16 to determine the optimal value of randomly selected predictors __mtry__:

```{r , echo=TRUE, include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
forest <- train(Credit ~ ., 
                 method = "rf", 
                 data = train_set,
                 tuneGrid = data.frame(mtry= seq(2, 16, 1))) #we test this sequence to determine the optimum mtry.
```

The best model uses three randomly selected predictors:

```{r , echo=FALSE, include=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
ggplot(forest, highlight = TRUE)
```

and, when tested on the test set, the random forest model gives an accuracy of 54.91%, which makes it the best model for this challenge.

The sensitivity improves especially for the the highest rating category (2 which is 'AA') when compared to the previous models, even though the 'AA' and 'CCC' ratings remain the most difficult to predict:

```{r , echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
cm_forest
```

Finally, with a random forest model, we can study the variable importance, with the function __varImp__ from the __caret__ package. The variable importance is computed by subtracting the out-of-bag accuracy for each predictor, averaged over all trees and standardized by dividing by the standard deviation^[https://topepo.github.io/caret/variable-importance.html]. Here is a plot of variable importance:

```{r , echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
ggplot(var_imp)
```

The plot suggests that the most important variables are the profitability indicator ratios (net profit margin, EBIT per revenue, pretax profit margin and operating profit margin), one cash flow ratios (operating cash flow margin) and one leverage ratio (debt ratio), consistently with rating methodologies. Interestingly, the sector and the rating agencies are not important for the model, meaning that on average the sector bias or the agency bias do not have an impact on the potential rating of a company.

## 4. Results

Things that I will stress: the data is biased so algo are biased. We have outliers and since we chsoe not to remove it is difficult to understand the kind of distribution the underlying data follows. We are kind of guessing for qda. For knn, see curse of dimensionality p. 582 data science book. 

## 5. Conclusion and future research

## 6. Appendix

### 1) Descriptive statistics

#### _Liquidity Ratios_

```{r liquidity_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(liquidity_stats, digits = 2)
```

#### _Profitability Indicator Ratios_

```{r profitability_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(profitability_stats, digits = 2)
```

#### _Operating Performance Ratios_

```{r operating_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(operating_stats, digits = 2)
```

#### _Leverage Ratios_

```{r leverage_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(leverage_stats, digits = 2)
```

#### _Cash Flow Indicator Ratios_

```{r cashflow_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(cashflow_stats, digits = 2)
```

#### _Valuation Ratio_

```{r valuation_stats, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
knitr::kable(valuation_stats, digits = 2)
```

